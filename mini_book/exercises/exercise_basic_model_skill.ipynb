{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Basic model skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modelskill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want do to a simple comparison between model and observation using the fmskill.compare method, but the following code snippet doesn't work.\n",
    "\n",
    "Change the code below, so that it works as intended. Hint: look at the documentation\n",
    "```\n",
    "help(fmskill.compare)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_mod = '../data/SW/ts_storm_4.dfs0'\n",
    "fn_obs = '../data/SW/eur_Hm0.dfs0'\n",
    "\n",
    "c = modelskillill.compare(fn_obs, fn_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have fixed the above snippet, you can continue to do the skill assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a timeseries of the comparison\n",
    "# * remove the default title\n",
    "# * set the limits of the y axis to cover the 0-6m interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your colleague, who is very skilled at Excel, wants to make a plot like this one:\n",
    "\n",
    "![](../images/excel_chart.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the .df property on the comparer object to save the obs and model timeseries as an Excel file (\"skill.xlsx\")\n",
    "# you might get an error \"No module named 'openpyxl'\", the solution is to run `pip install openpyxl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the default skill metrics using the skill method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the skill using the mean absolute percentage error and max error, use the metrics argument\n",
    "# c.skill(metrics=[__,__])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the hit_ratio metric from modelskillill.metrics\n",
    "# and calculate the ratio when the deviation between model and observation is less than 0.5 m\n",
    "# hint: use the Observation and Model columns of the dataframe from the .df property you used above\n",
    "\n",
    "# is the hit ratio ~0.95 ? Does it match with your expectation based on the timeseries plot?\n",
    "# what about a deviation of less than 0.1m? Pretty accurate wave model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hit_ratio(c.df.Observation, __, a=__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the distribution of modelled and observed values, using the .hist method\n",
    "# change the number of bins to 10"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4041ee05ab07c15354d6207e763f17a216c3f5ccf08906343c2b4fd3fa7a6fb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
